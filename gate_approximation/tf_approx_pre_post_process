import os
import time
from typing import *
from utils import *
from tf_qc import *
from tensorflow.keras import layers
import datetime
import itertools
import numpy as np

angle_type = float_type
f64_0 = tf.constant(0., dtype=tf.float64)


class UniformComplexReal(tf.initializers.RandomUniform):
    def __init__(self, *args):
        super(UniformComplexReal, self).__init__(*args)

    def __call__(self, shape, dtype=None):
        if dtype is None:
            dtype = complex_type
        value = tf.initializers.RandomUniform.__call__(self, shape)
        return tf.cast(tf.complex(value, 0.), dtype=complex_type)


class QFTULayer(layers.Layer):
    def __init__(self, n_qubits=4):
        super(QFTULayer, self).__init__()
        self.n_qubits = None

    def build(self, input_shape):
        self.n_qubits = input_shape[-2].bit_length() - 1
        theta_init = tf.random_uniform_initializer(0, 2*π)
        n_thetas = sum(range(self.n_qubits))
        self.thetas = tf.Variable(initial_value=theta_init(shape=(n_thetas,), dtype=angle_type),
                                 trainable=True, name='thetas')

    def call(self, inputs, thetas=None):
        self.qft_U = self.matrix(thetas)
        return tf.matmul(self.qft_U, inputs)

    def matrix(self, thetas=None):
        if thetas:
            return qft_U(self.n_qubits, I4, thetas)
        else:
            return qft_U(self.n_qubits, I4, self.thetas)


# TEST
# x = tf.ones((10000000, 2**4, 1), dtype=complex_type)
# qft_u_layer = QFTULayer()
# t = time.process_time()
# qft_u_layer(x)
# exit()


class U3Layer(layers.Layer):
    def __init__(self):
        super(U3Layer, self).__init__()
        self.U3 = None
        self.thetas = None

    def build(self, input_shape):
        theta_init = tf.random_uniform_initializer(0, 2 * π)
        n_qubits = input_shape[-2].bit_length() - 1
        self.thetas = [tf.Variable(initial_value=theta_init(shape=(3,), dtype=angle_type),
                                   trainable=True,
                                   dtype=angle_type) for _ in range(n_qubits)]

    def call(self, inputs, thetas=None):
        self.U3 = self.matrix(thetas)
        return self.U3 @ inputs

    def matrix(self, thetas=None):
        if thetas:
            return U3(*thetas)
        else:
            return U3(*self.thetas)


class IQFTLayer(layers.Layer):
    def __init__(self):
        super(IQFTLayer, self).__init__()
        self.n_qubits = None

    def build(self, input_shape):
        self.n_qubits = input_shape[-2].bit_length() - 1

    def call(self, inputs, **kwargs):
        self.IQFT = iqft(self.n_qubits, I4)
        return tf.matmul(self.IQFT, inputs)


class PrePostQFTUIQFT(tf.keras.Model):
    def __init__(self, nn=False):
        super(PrePostQFTUIQFT, self).__init__()
        if nn:
            tf.keras.layers.Dense()
        self.U3_in = U3Layer()
        self.QFT_U = QFTULayer()
        self.U3_out = U3Layer()
        self.IQFT = IQFTLayer()

    def call(self, inputs, training=None, mask=None):
        x = self.U3_in(inputs)
        x = self.QFT_U(x)
        x = self.U3_out(x)
        x = self.IQFT(x)
        return x


class MeanNorm(tf.losses.Loss):
    def call(self, y_true, y_pred):
        # y_pred = tf.convert_to_tensor(y_pred)
        diff = y_true - y_pred
        norms = tf.cast(tf.norm(diff, axis=[-2, -1]), dtype=float_type)
        mean_norm = tf.reduce_mean(norms)
        return mean_norm
# TEST
# x = tf.constant([1,2,3,4], shape=(2,2,1), dtype=complex_type)
# assert round(MeanNorm()(x, 2*x).numpy(), 5) == 3.61803
# TEST END


class Mean1mFidelity(tf.losses.Loss):
    def call(self, y_true, y_pred):
        fidelies = tf.square(tf.abs(tf.reduce_sum(tf.multiply(y_true, y_pred), axis=[-2, -1])))
        meanFilelity = tf.reduce_mean(fidelies)
        return 1 - meanFilelity
# TEST
x = tf.constant([1/math.sqrt(3), 1/math.sqrt(3), 1/math.sqrt(3), 1/math.sqrt(2), 1/math.sqrt(2), 0], shape=(2,3,1), dtype=complex_type)
y = tf.constant([1, 0, 0, 1, 0, 0], shape=(2,3,1), dtype=complex_type)
assert round(Mean1mFidelity()(x, y).numpy(), 5) == round(1 - (1/3 + 1/2)/2, 5)
# TEST END

# Data is just all the kinds of vectors that we might get
N = 4
vectors = list(map(list, list(itertools.product([0, 1], repeat=2**N))))[1:]  # Skip the zero-vector as it creates problems
vectors = tf.constant(vectors, dtype=complex_type, shape=(len(vectors), 2**N, 1))
# normalize
vectors = tf.math.xdivy(vectors, tf.sqrt(tf.reduce_sum(vectors, axis=1, keepdims=True)))
# for i in range(len(vectors)):
#     n = math.sqrt(sum(vectors[i]))
#     for j in range(len(vectors[i])):
#         vectors[i][j] = vectors[i][j]/math.sqrt(n)

input = tf.constant(vectors, dtype=complex_type, shape=(len(vectors), 2**N, 1))
output = input

# print(Mean1mFidelity()(input[500:510], input[300:310]).numpy())
# exit()

pre_post_model = PrePostQFTUIQFT()
optimizer = tf.optimizers.Adagrad(0.025)
loss = Mean1mFidelity()
pre_post_model.compile(optimizer, loss=loss)

# Fitting
current_time = datetime.datetime.now().strftime("%Y.%m.%d-%H:%M:%S")
log_path = './logs/tf_approx_pre_post_process/' + current_time
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1, profile_batch=0)
pre_post_model.fit(input, output, batch_size=1024, epochs=1000, callbacks=[tensorboard_callback])
print(*pre_post_model.variables, sep='\n')
print(pre_post_model.summary())

result = pre_post_model.U3_out.matrix() @ pre_post_model.QFT_U.matrix() @ pre_post_model.U3_in.matrix()
print(ndtotext(result.numpy()))

# class PrePostApprox(tf.keras.Model):
#
#     def __init__(self):
#         super(PrePostApprox, self).__init__()
#         self.qft_tensor = None
#         self.qft_U_tensor = None
#
#     def build(self, input_shape):
#         N = 4
#         n_t = sum(range(N))
#         uniform = lambda shape, dtype: tf.random.uniform(shape, 0, 2 * π, dtype)
#         t_pre = [self.add_weight(name='t_pre_'+str(i), shape=(3,), dtype=tf.float64, initializer=uniform) for i in range(4)]
#         t_post = [self.add_weight(name='t_post_'+str(i), shape=(3,), dtype=tf.float64, initializer=uniform) for i in range(4)]
#         t = self.add_weight(name='t', shape=(n_t,), dtype=tf.float64, initializer=uniform)
#         qft_tensor = qft(N, I4)
#         qft_U_tensor = U3(*t_pre)
#         qft_U_tensor = qft_U(N, qft_U_tensor, t)
#         qft_U_tensor = U3(*t_post) @ qft_U_tensor
#         self.qft_tensor = qft_tensor
#         self.qft_U_tensor = qft_U_tensor
#
#     def losses(self):
#         diff = self.qft_tensor - self.qft_U_tensor
#         return [tf.cast(tf.reduce_sum(tf.square(tf.norm(diff))), tf.float64)]
#
#     def call(self, inputs, training=None, mask=None):
#         return self.get_losses_for(None)
#
#
# model = PrePostApprox()
#
# # print('loss:', model())
#
# current_time = datetime.datetime.now().strftime("%Y.%m.%d-%H:%M:%S")
# log_path = './logs/tf_approx_pre_post_process/SGD/' + current_time
# summary_writer = tf.summary.create_file_writer(log_path)
# avg_loss = tf.metrics.Mean(name='loss', dtype=tf.float32)
# opt = tf.keras.optimizers.SGD()
# model.compile(opt)
# model.fit(tf.constant(1), tf.constant(1))
# model.save_weights(log_path)
# exit()
#
# # start_time = time.time()
# # with summary_writer.as_default():
# #     for step in range(25000):
# #         train_step(model, opt)
# #         if step % 500 == 0:
# #             tf.summary.scalar('loss', model, step)
# # print('time:', time.time() - start_time, "seconds")
# # print('loss:', model)
# # print('final vars', model.trainable_variables)
# # print(ndtotext(model.qft_U_tensor.numpy()))
